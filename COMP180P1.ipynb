{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiaranocentini/chiaranocentini/blob/main/COMP180P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMP 180 Project 1\n",
        "For this project, I will be reading in a text file from an old class (Environmental Science 101) that has my reflection for the first episode of \"Our Planet.\" I will perform a series of codes to extract insights on the word counts for this text file. I will also perform codes to manipulate and create a working directory for this text file."
      ],
      "metadata": {
        "id": "FhSLDXMhCVME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCNx_4cb1X3_",
        "outputId": "457ffd63-7be3-4a22-b022-2d9f4ca8f7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part A - Setup"
      ],
      "metadata": {
        "id": "xy75TKxxgM5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the built-in os module to check the current working directory and contents of the cwd.\n",
        "import os\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current Working Directory:\", current_directory)\n",
        "\n",
        "# Use string formatting to print the current working directory and list of contents.\n",
        "current_directory = os.getcwd()\n",
        "print(\"\\nCurrent Working Directory: {}\".format(current_directory))\n",
        "\n",
        "directory_contents = os.listdir(current_directory)\n",
        "print(\"Contents of the Current Working Directory:\")\n",
        "for item in directory_contents:\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "-h4A0IvUD4GK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5311d7-a298-44f1-9010-b2ca3e368dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content\n",
            "\n",
            "Current Working Directory: /content\n",
            "Contents of the Current Working Directory:\n",
            ".config\n",
            "COMP 180 Project 1.txt\n",
            "drive\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXvjShdMCCIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f59363f-b39d-41c7-a677-c2d19eeb4647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project directory 'project-1' created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create a project dirctory in the current working directory for project-related work.\n",
        "# Example: /content/project-1\n",
        "import os\n",
        "\n",
        "project_directory = \"project-1\"\n",
        "current_directory = os.getcwd()\n",
        "project_path = os.path.join(current_directory, project_directory)\n",
        "os.mkdir(project_path)\n",
        "\n",
        "if os.path.exists(project_path):\n",
        "    print(\"Project directory '{}' created successfully.\".format(project_directory))\n",
        "else:\n",
        "    print(\"Failed to create project directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change from the current directory to the project directory. Check that the cwd is\n",
        "# now the project directory. Tip: use Notebook 06 as reference (os.chdir())\n",
        "import os\n",
        "\n",
        "os.chdir(project_path)\n",
        "\n",
        "if os.getcwd() == project_path:\n",
        "    print(\"Current working directory changed to the project directory '{}'.\".format(project_directory))\n",
        "else:\n",
        "    print(\"Failed to change current working directory.\")"
      ],
      "metadata": {
        "id": "VBoYcYvcRf81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65b7708-7278-47a1-d73e-fb735e6bcf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory changed to the project directory 'project-1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B - Create, Read, and Store Data"
      ],
      "metadata": {
        "id": "xYyXO7zJgTmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you're project directory is set up, create a text file and add some text to be processed.\n",
        "1. Open a new word document and copy/paste at least one page of any text of your choosing. Be sure to paste as plain text. Text can be literature, scientific research publication, etc.\n",
        "2. Save the doc as a .txt file.\n",
        "3. Upload the file to the project directory just created. To upload, press the folder icon on the left menu panel, click the page icon with the up arrow, select the file you wish to upload, then drag the file to the project folder.\n",
        "\n",
        "\n",
        "\n",
        "> * Please note that when you close the notebook, the directories created and files uploaded will be removed automatically. To continue working, earlier commands need to be rerun. And to submit the assignment, the .txt data file needs to be submitted along with the notebook.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lEsynmMuSAl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next read the text into a data container structure.\n",
        "1. Read the text line by line.\n",
        "2. Split each line and add the words to a dictionary. The word is the 'key' and the initial count 'value' for each word is 1.\n",
        "3. Each time an existing word is encountered, the count is increased by 1.\n"
      ],
      "metadata": {
        "id": "w-n-h89zWxwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the text from the .txt file.\n",
        "# Tip: see read(), readline(), and readlines() references in Notebook 06.\n",
        "file_path = os.path.join(project_path, \"COMP 180 Project 1.txt\")\n",
        "\n",
        "\n",
        "try:\n",
        "    with open(file_path, \"r\") as file:\n",
        "        text_content = file.read()\n",
        "        print(\"Text from the file:\")\n",
        "        print(text_content)\n",
        "except FileNotFoundError:\n",
        "    print(\"File '{}' not found.\".format(file_path))\n"
      ],
      "metadata": {
        "id": "iPsXGMzJSA0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a21a51-034e-421a-8a0d-732f459acac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text from the file:\n",
            "﻿In the first episode of “Our Planet,” the audience is taken into the beating of Earth’s jungles. Through stunning visuals and storytelling, you get to witness the amazing web of life that exists within these jungles. Among this episode is a bittersweet note, reminding us of the delicate balance these ecosystems maintain and the threats they face due to human actions. In addition, the episode meticulously showcases the symbiotic relationships between diverse species inhabiting these jungles. For instance, from the towering canopy-dwellers to the myriad of organisms thriving on the forest floor. However, it also confronts the harsh reality of human-induced threats these ecosystems face, underlining the urgent need for conservation efforts to protect these habitats and their inhabitants.\n",
            "In connection from in-class learning, this portrayal of symbiotic relationships between diverse species and the threats facing them relates to what we learned in chapter 8. For instance, class 11 focused on the first part of biodiversity conservation. The in-class assignments involved looking through a list of Illinois endangered and threatened species and determining which groups are the most vulnerable. Similarly, the reading for chapter 8.5 relates directly to the “threats to biodiversity” that is expounded on in the first episode. Just like the episode delves deep into how humans are the major contributors to biodiversity threats, reading 8.5 explores the various factors of how humans affect biodiversity. It provides further insight and data to accompany the imaging seen in the first episode. \n",
            "\n",
            "\n",
            "I watched this episode with my dad because we both really enjoy nature shows, and he was very interested in watching this show when I presented him with this final project. Since I was home at the time, I took the opportunity to include him in my reflection. My dad works in an agricultural company (Case New Holland Industrial) and he noted how less biodiversity affects his company. Less biodiversity means less organisms and microorganisms that are critical for pollination, cleaning water, and maintaining the soil fertile. He claims that a decrease in biodiversity makes it more difficult for the agriculture industry to grow crops that are needed to feed the surging human population. This conversation reinforced the idea of the interdependence of organisms in an ecosystem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tip: First process one line of text and check results manually by printing the line and\n",
        "# printing the dictionary to compare results of each.\n",
        "# Process first line here.\n",
        "\n",
        "\n",
        "def process_line(line):\n",
        "   words = line.split()\n",
        "   word_count = {}\n",
        "   for word in words:\n",
        "       if word in word_count:\n",
        "           word_count[word] += 1\n",
        "       else:\n",
        "           word_count[word] = 1\n",
        "   return word_count\n",
        "\n",
        "\n",
        "first_line = text_content.split('\\n')[0]\n",
        "print(\"First line:\", first_line)\n",
        "word_count = process_line(first_line)\n",
        "print(\"Word count dictionary for first line:\", word_count)\n",
        "\n",
        "# Now process the entire file by splitting each line of the entire .txt file into\n",
        "# words and adding the words to a dictionary.\n",
        "# Enter code here.\n",
        "\n",
        "# Now process the entire file by splitting each line of the entire .txt file into\n",
        "# words and adding the words to a dictionary.\n",
        "# Enter code here.\n",
        "\n",
        "def process_file(file_content):\n",
        "    word_count_file = {}\n",
        "    lines = file_content.split('\\n')\n",
        "    for line in lines:\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            if word in word_count_file:\n",
        "                word_count_file[word] += 1\n",
        "            else:\n",
        "                word_count_file[word] = 1\n",
        "    return word_count_file\n",
        "\n",
        "word_count_file = process_file(text_content)\n",
        "print(\"\\nWord count dictionary for entire file:\", word_count_file)\n"
      ],
      "metadata": {
        "id": "p4XXNnJmA5uW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af35d1eb-73eb-4071-f607-cb1187c5e085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First line: ﻿In the first episode of “Our Planet,” the audience is taken into the beating of Earth’s jungles. Through stunning visuals and storytelling, you get to witness the amazing web of life that exists within these jungles. Among this episode is a bittersweet note, reminding us of the delicate balance these ecosystems maintain and the threats they face due to human actions. In addition, the episode meticulously showcases the symbiotic relationships between diverse species inhabiting these jungles. For instance, from the towering canopy-dwellers to the myriad of organisms thriving on the forest floor. However, it also confronts the harsh reality of human-induced threats these ecosystems face, underlining the urgent need for conservation efforts to protect these habitats and their inhabitants.\n",
            "Word count dictionary for first line: {'\\ufeffIn': 1, 'the': 13, 'first': 1, 'episode': 3, 'of': 6, '“Our': 1, 'Planet,”': 1, 'audience': 1, 'is': 2, 'taken': 1, 'into': 1, 'beating': 1, 'Earth’s': 1, 'jungles.': 3, 'Through': 1, 'stunning': 1, 'visuals': 1, 'and': 3, 'storytelling,': 1, 'you': 1, 'get': 1, 'to': 4, 'witness': 1, 'amazing': 1, 'web': 1, 'life': 1, 'that': 1, 'exists': 1, 'within': 1, 'these': 5, 'Among': 1, 'this': 1, 'a': 1, 'bittersweet': 1, 'note,': 1, 'reminding': 1, 'us': 1, 'delicate': 1, 'balance': 1, 'ecosystems': 2, 'maintain': 1, 'threats': 2, 'they': 1, 'face': 1, 'due': 1, 'human': 1, 'actions.': 1, 'In': 1, 'addition,': 1, 'meticulously': 1, 'showcases': 1, 'symbiotic': 1, 'relationships': 1, 'between': 1, 'diverse': 1, 'species': 1, 'inhabiting': 1, 'For': 1, 'instance,': 1, 'from': 1, 'towering': 1, 'canopy-dwellers': 1, 'myriad': 1, 'organisms': 1, 'thriving': 1, 'on': 1, 'forest': 1, 'floor.': 1, 'However,': 1, 'it': 1, 'also': 1, 'confronts': 1, 'harsh': 1, 'reality': 1, 'human-induced': 1, 'face,': 1, 'underlining': 1, 'urgent': 1, 'need': 1, 'for': 1, 'conservation': 1, 'efforts': 1, 'protect': 1, 'habitats': 1, 'their': 1, 'inhabitants.': 1}\n",
            "\n",
            "Word count dictionary for entire file: {'\\ufeffIn': 1, 'the': 31, 'first': 4, 'episode': 5, 'of': 12, '“Our': 1, 'Planet,”': 1, 'audience': 1, 'is': 3, 'taken': 1, 'into': 2, 'beating': 1, 'Earth’s': 1, 'jungles.': 3, 'Through': 1, 'stunning': 1, 'visuals': 1, 'and': 11, 'storytelling,': 1, 'you': 1, 'get': 1, 'to': 12, 'witness': 1, 'amazing': 1, 'web': 1, 'life': 1, 'that': 5, 'exists': 1, 'within': 1, 'these': 5, 'Among': 1, 'this': 5, 'a': 3, 'bittersweet': 1, 'note,': 1, 'reminding': 1, 'us': 1, 'delicate': 1, 'balance': 1, 'ecosystems': 2, 'maintain': 1, 'threats': 3, 'they': 1, 'face': 1, 'due': 1, 'human': 2, 'actions.': 1, 'In': 2, 'addition,': 1, 'meticulously': 1, 'showcases': 1, 'symbiotic': 2, 'relationships': 2, 'between': 2, 'diverse': 2, 'species': 3, 'inhabiting': 1, 'For': 2, 'instance,': 2, 'from': 2, 'towering': 1, 'canopy-dwellers': 1, 'myriad': 1, 'organisms': 3, 'thriving': 1, 'on': 3, 'forest': 1, 'floor.': 1, 'However,': 1, 'it': 2, 'also': 1, 'confronts': 1, 'harsh': 1, 'reality': 1, 'human-induced': 1, 'face,': 1, 'underlining': 1, 'urgent': 1, 'need': 1, 'for': 4, 'conservation': 1, 'efforts': 1, 'protect': 1, 'habitats': 1, 'their': 1, 'inhabitants.': 1, 'connection': 1, 'in-class': 2, 'learning,': 1, 'portrayal': 1, 'facing': 1, 'them': 1, 'relates': 2, 'what': 1, 'we': 2, 'learned': 1, 'in': 8, 'chapter': 2, '8.': 1, 'class': 1, '11': 1, 'focused': 1, 'part': 1, 'biodiversity': 5, 'conservation.': 1, 'The': 1, 'assignments': 1, 'involved': 1, 'looking': 1, 'through': 1, 'list': 1, 'Illinois': 1, 'endangered': 1, 'threatened': 1, 'determining': 1, 'which': 1, 'groups': 1, 'are': 4, 'most': 1, 'vulnerable.': 1, 'Similarly,': 1, 'reading': 2, '8.5': 2, 'directly': 1, '“threats': 1, 'biodiversity”': 1, 'expounded': 1, 'episode.': 2, 'Just': 1, 'like': 1, 'delves': 1, 'deep': 1, 'how': 3, 'humans': 2, 'major': 1, 'contributors': 1, 'threats,': 1, 'explores': 1, 'various': 1, 'factors': 1, 'affect': 1, 'biodiversity.': 1, 'It': 1, 'provides': 1, 'further': 1, 'insight': 1, 'data': 1, 'accompany': 1, 'imaging': 1, 'seen': 1, 'I': 4, 'watched': 1, 'with': 2, 'my': 2, 'dad': 2, 'because': 1, 'both': 1, 'really': 1, 'enjoy': 1, 'nature': 1, 'shows,': 1, 'he': 2, 'was': 2, 'very': 1, 'interested': 1, 'watching': 1, 'show': 1, 'when': 1, 'presented': 1, 'him': 2, 'final': 1, 'project.': 1, 'Since': 1, 'home': 1, 'at': 1, 'time,': 1, 'took': 1, 'opportunity': 1, 'include': 1, 'reflection.': 1, 'My': 1, 'works': 1, 'an': 2, 'agricultural': 1, 'company': 1, '(Case': 1, 'New': 1, 'Holland': 1, 'Industrial)': 1, 'noted': 1, 'less': 2, 'affects': 1, 'his': 1, 'company.': 1, 'Less': 1, 'means': 1, 'microorganisms': 1, 'critical': 1, 'pollination,': 1, 'cleaning': 1, 'water,': 1, 'maintaining': 1, 'soil': 1, 'fertile.': 1, 'He': 1, 'claims': 1, 'decrease': 1, 'makes': 1, 'more': 1, 'difficult': 1, 'agriculture': 1, 'industry': 1, 'grow': 1, 'crops': 1, 'needed': 1, 'feed': 1, 'surging': 1, 'population.': 1, 'This': 1, 'conversation': 1, 'reinforced': 1, 'idea': 1, 'interdependence': 1, 'ecosystem.': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add code here to check that keys/values have expected format and logical/reasonable\n",
        "# results.\n",
        "\n",
        "if all(isinstance(key, str) for key in word_count_file.keys()):\n",
        "    print(\"All keys are strings.\")\n",
        "else:\n",
        "    print(\"Error: Not all keys are strings.\")\n",
        "\n",
        "if all(isinstance(value, int) for value in word_count_file.values()):\n",
        "    print(\"All values are integers.\")\n",
        "else:\n",
        "    print(\"Error: Not all values are integers.\")\n",
        "\n",
        "\n",
        "\n",
        "# Also check for quality control issues. Are identical words counted separately depending\n",
        "# on case or presence of punctuation?\n",
        "# Tip: filter out punctuation and make all words lower case before adding to the\n",
        "# dictionary.\n",
        "# Enter revised code here.\n",
        "\n",
        "import string\n",
        "\n",
        "def process_line(line, word_count):\n",
        "    line = line.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "\n",
        "word_count_file = {}\n",
        "for line in text_content.split('\\n'):\n",
        "    process_line(line, word_count_file)\n",
        "\n",
        "identical_words_with_punctuation = sum(word_count_file.values())\n",
        "word_count_no_punctuation = {}\n",
        "process_line(text_content, word_count_no_punctuation)\n",
        "identical_words_without_punctuation = sum(word_count_no_punctuation.values())\n",
        "\n",
        "if identical_words_with_punctuation == identical_words_without_punctuation:\n",
        "    print(\"\\nNo quality control issues found.\")\n",
        "else:\n",
        "    print(\"Quality control issues found.\")\n",
        "\n",
        "print(\"\\nWord count dictionary for the entire file (after quality control):\", word_count_file)\n"
      ],
      "metadata": {
        "id": "5G_JN_gxA5Ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa8ea7b-9bc6-40d0-adf7-03a4db270557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All keys are strings.\n",
            "All values are integers.\n",
            "\n",
            "No quality control issues found.\n",
            "\n",
            "Word count dictionary for the entire file (after quality control): {'\\ufeffin': 1, 'the': 32, 'first': 4, 'episode': 7, 'of': 12, '“our': 1, 'planet”': 1, 'audience': 1, 'is': 3, 'taken': 1, 'into': 2, 'beating': 1, 'earth’s': 1, 'jungles': 3, 'through': 2, 'stunning': 1, 'visuals': 1, 'and': 11, 'storytelling': 1, 'you': 1, 'get': 1, 'to': 12, 'witness': 1, 'amazing': 1, 'web': 1, 'life': 1, 'that': 5, 'exists': 1, 'within': 1, 'these': 5, 'among': 1, 'this': 6, 'a': 3, 'bittersweet': 1, 'note': 1, 'reminding': 1, 'us': 1, 'delicate': 1, 'balance': 1, 'ecosystems': 2, 'maintain': 1, 'threats': 4, 'they': 1, 'face': 2, 'due': 1, 'human': 2, 'actions': 1, 'in': 10, 'addition': 1, 'meticulously': 1, 'showcases': 1, 'symbiotic': 2, 'relationships': 2, 'between': 2, 'diverse': 2, 'species': 3, 'inhabiting': 1, 'for': 6, 'instance': 2, 'from': 2, 'towering': 1, 'canopydwellers': 1, 'myriad': 1, 'organisms': 3, 'thriving': 1, 'on': 3, 'forest': 1, 'floor': 1, 'however': 1, 'it': 3, 'also': 1, 'confronts': 1, 'harsh': 1, 'reality': 1, 'humaninduced': 1, 'underlining': 1, 'urgent': 1, 'need': 1, 'conservation': 2, 'efforts': 1, 'protect': 1, 'habitats': 1, 'their': 1, 'inhabitants': 1, 'connection': 1, 'inclass': 2, 'learning': 1, 'portrayal': 1, 'facing': 1, 'them': 1, 'relates': 2, 'what': 1, 'we': 2, 'learned': 1, 'chapter': 2, '8': 1, 'class': 1, '11': 1, 'focused': 1, 'part': 1, 'biodiversity': 6, 'assignments': 1, 'involved': 1, 'looking': 1, 'list': 1, 'illinois': 1, 'endangered': 1, 'threatened': 1, 'determining': 1, 'which': 1, 'groups': 1, 'are': 4, 'most': 1, 'vulnerable': 1, 'similarly': 1, 'reading': 2, '85': 2, 'directly': 1, '“threats': 1, 'biodiversity”': 1, 'expounded': 1, 'just': 1, 'like': 1, 'delves': 1, 'deep': 1, 'how': 3, 'humans': 2, 'major': 1, 'contributors': 1, 'explores': 1, 'various': 1, 'factors': 1, 'affect': 1, 'provides': 1, 'further': 1, 'insight': 1, 'data': 1, 'accompany': 1, 'imaging': 1, 'seen': 1, 'i': 4, 'watched': 1, 'with': 2, 'my': 3, 'dad': 2, 'because': 1, 'both': 1, 'really': 1, 'enjoy': 1, 'nature': 1, 'shows': 1, 'he': 3, 'was': 2, 'very': 1, 'interested': 1, 'watching': 1, 'show': 1, 'when': 1, 'presented': 1, 'him': 2, 'final': 1, 'project': 1, 'since': 1, 'home': 1, 'at': 1, 'time': 1, 'took': 1, 'opportunity': 1, 'include': 1, 'reflection': 1, 'works': 1, 'an': 2, 'agricultural': 1, 'company': 2, 'case': 1, 'new': 1, 'holland': 1, 'industrial': 1, 'noted': 1, 'less': 3, 'affects': 1, 'his': 1, 'means': 1, 'microorganisms': 1, 'critical': 1, 'pollination': 1, 'cleaning': 1, 'water': 1, 'maintaining': 1, 'soil': 1, 'fertile': 1, 'claims': 1, 'decrease': 1, 'makes': 1, 'more': 1, 'difficult': 1, 'agriculture': 1, 'industry': 1, 'grow': 1, 'crops': 1, 'needed': 1, 'feed': 1, 'surging': 1, 'population': 1, 'conversation': 1, 'reinforced': 1, 'idea': 1, 'interdependence': 1, 'ecosystem': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part C - Evaluate Results\n",
        "\n",
        "> Which word has the max count value? What are the top 5 words?\n",
        "\n"
      ],
      "metadata": {
        "id": "fGgpb17hIXgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the word ('key') that has the highest count ('value'). Enter code here.\n",
        "max_word = max(word_count_file, key=word_count_file.get)\n",
        "max_count = word_count_file[max_word]\n",
        "\n",
        "print(\"Word with the highest count:\", max_word)\n",
        "print(\"Count:\", max_count)\n",
        "\n",
        "# Which 5 words are used the most (have the highest count values)? Enter code here.\n",
        "# Tip: Create key and value lists by casting, list(my_dict.keys()), list(my_dict.values())\n",
        "keys = list(word_count_file.keys())\n",
        "values = list(word_count_file.values())\n",
        "\n",
        "def get_count(item):\n",
        "    return item[1]\n",
        "\n",
        "top_5_words = sorted(word_count_file.items(), key=get_count, reverse=True)[:5]\n",
        "\n",
        "print(\"\\nTop 5 words with the highest counts:\")\n",
        "for word, count in top_5_words:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Write test code to confirm your top 5 results\n",
        "# Tip: print original dict or dict items (my_dict.items()) and review, or use top five\n",
        "# words found above as keys to query original dict (my_dict[top_five_word]).\n",
        "# Compare test results with results above.\n",
        "\n",
        "print(\"\\nTest code to confirm the top 5 results:\")\n",
        "print(\"\\nOriginal word count dictionary:\")\n",
        "print(word_count_file.items())\n",
        "\n",
        "print(\"Using top five words to query original dictionary:\")\n",
        "for word, count in top_5_words:\n",
        "    if word in word_count_file:\n",
        "        count = word_count_file[word]\n",
        "        print(f\"{word}: {count}\")\n",
        "    else:\n",
        "        print(f\"{word} not found in word count dictionary.\")\n",
        "\n",
        "print(\"\\nComparison with top 5 results:\")\n",
        "for word, count in top_5_words:\n",
        "    count_above = word_count_file[word]\n",
        "    count_test = word_count_file[word]\n",
        "    print(f\"{word}: Result from step above - {count_above}, Test result - {count_test}, Matches: {count_above == count_test}\")"
      ],
      "metadata": {
        "id": "OhbpYmXiIxRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae20c11-2f58-46f0-93ac-8ee77b3021ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word with the highest count: the\n",
            "Count: 32\n",
            "\n",
            "Top 5 words with the highest counts:\n",
            "the: 32\n",
            "of: 12\n",
            "to: 12\n",
            "and: 11\n",
            "in: 10\n",
            "\n",
            "Test code to confirm the top 5 results:\n",
            "\n",
            "Original word count dictionary:\n",
            "dict_items([('\\ufeffin', 1), ('the', 32), ('first', 4), ('episode', 7), ('of', 12), ('“our', 1), ('planet”', 1), ('audience', 1), ('is', 3), ('taken', 1), ('into', 2), ('beating', 1), ('earth’s', 1), ('jungles', 3), ('through', 2), ('stunning', 1), ('visuals', 1), ('and', 11), ('storytelling', 1), ('you', 1), ('get', 1), ('to', 12), ('witness', 1), ('amazing', 1), ('web', 1), ('life', 1), ('that', 5), ('exists', 1), ('within', 1), ('these', 5), ('among', 1), ('this', 6), ('a', 3), ('bittersweet', 1), ('note', 1), ('reminding', 1), ('us', 1), ('delicate', 1), ('balance', 1), ('ecosystems', 2), ('maintain', 1), ('threats', 4), ('they', 1), ('face', 2), ('due', 1), ('human', 2), ('actions', 1), ('in', 10), ('addition', 1), ('meticulously', 1), ('showcases', 1), ('symbiotic', 2), ('relationships', 2), ('between', 2), ('diverse', 2), ('species', 3), ('inhabiting', 1), ('for', 6), ('instance', 2), ('from', 2), ('towering', 1), ('canopydwellers', 1), ('myriad', 1), ('organisms', 3), ('thriving', 1), ('on', 3), ('forest', 1), ('floor', 1), ('however', 1), ('it', 3), ('also', 1), ('confronts', 1), ('harsh', 1), ('reality', 1), ('humaninduced', 1), ('underlining', 1), ('urgent', 1), ('need', 1), ('conservation', 2), ('efforts', 1), ('protect', 1), ('habitats', 1), ('their', 1), ('inhabitants', 1), ('connection', 1), ('inclass', 2), ('learning', 1), ('portrayal', 1), ('facing', 1), ('them', 1), ('relates', 2), ('what', 1), ('we', 2), ('learned', 1), ('chapter', 2), ('8', 1), ('class', 1), ('11', 1), ('focused', 1), ('part', 1), ('biodiversity', 6), ('assignments', 1), ('involved', 1), ('looking', 1), ('list', 1), ('illinois', 1), ('endangered', 1), ('threatened', 1), ('determining', 1), ('which', 1), ('groups', 1), ('are', 4), ('most', 1), ('vulnerable', 1), ('similarly', 1), ('reading', 2), ('85', 2), ('directly', 1), ('“threats', 1), ('biodiversity”', 1), ('expounded', 1), ('just', 1), ('like', 1), ('delves', 1), ('deep', 1), ('how', 3), ('humans', 2), ('major', 1), ('contributors', 1), ('explores', 1), ('various', 1), ('factors', 1), ('affect', 1), ('provides', 1), ('further', 1), ('insight', 1), ('data', 1), ('accompany', 1), ('imaging', 1), ('seen', 1), ('i', 4), ('watched', 1), ('with', 2), ('my', 3), ('dad', 2), ('because', 1), ('both', 1), ('really', 1), ('enjoy', 1), ('nature', 1), ('shows', 1), ('he', 3), ('was', 2), ('very', 1), ('interested', 1), ('watching', 1), ('show', 1), ('when', 1), ('presented', 1), ('him', 2), ('final', 1), ('project', 1), ('since', 1), ('home', 1), ('at', 1), ('time', 1), ('took', 1), ('opportunity', 1), ('include', 1), ('reflection', 1), ('works', 1), ('an', 2), ('agricultural', 1), ('company', 2), ('case', 1), ('new', 1), ('holland', 1), ('industrial', 1), ('noted', 1), ('less', 3), ('affects', 1), ('his', 1), ('means', 1), ('microorganisms', 1), ('critical', 1), ('pollination', 1), ('cleaning', 1), ('water', 1), ('maintaining', 1), ('soil', 1), ('fertile', 1), ('claims', 1), ('decrease', 1), ('makes', 1), ('more', 1), ('difficult', 1), ('agriculture', 1), ('industry', 1), ('grow', 1), ('crops', 1), ('needed', 1), ('feed', 1), ('surging', 1), ('population', 1), ('conversation', 1), ('reinforced', 1), ('idea', 1), ('interdependence', 1), ('ecosystem', 1)])\n",
            "Using top five words to query original dictionary:\n",
            "the: 32\n",
            "of: 12\n",
            "to: 12\n",
            "and: 11\n",
            "in: 10\n",
            "\n",
            "Comparison with top 5 results:\n",
            "the: Result from step above - 32, Test result - 32, Matches: True\n",
            "of: Result from step above - 12, Test result - 12, Matches: True\n",
            "to: Result from step above - 12, Test result - 12, Matches: True\n",
            "and: Result from step above - 11, Test result - 11, Matches: True\n",
            "in: Result from step above - 10, Test result - 10, Matches: True\n"
          ]
        }
      ]
    }
  ]
}